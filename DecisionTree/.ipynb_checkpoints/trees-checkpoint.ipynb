{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算给定数据集的香农熵\n",
    "def calcShannonEnt(dataSet):\n",
    "    # 求list的长度，表示计算参与训练的数据量\n",
    "    numEntries = len(dataSet)\n",
    "    # 计算分类标签label出现的次数\n",
    "    labelCounts = {}\n",
    "    # the the number of unique elements and their occurance\n",
    "    for featVec in dataSet:\n",
    "        # 将当前实例的标签存储，即每一行数据的最后一个数据代表的是标签\n",
    "        currentLabel = featVec[-1]\n",
    "        # 为所有可能的分类创建字典，如果当前的键值不存在，则扩展字典并将当前键值加入字典。每个键值都记录了当前类别出现的次数。\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    # 对于 label 标签的占比，求出 label 标签的香农熵\n",
    "    shannoEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        # 使用所有类标签的发生频率计算类别出现的概率。\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        # 计算香农熵，以 2 为底求对数\n",
    "        shannoEnt -= prob * log(prob,2)\n",
    "    return shannoEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import trees\n",
    "# myDat, labels = trees.createDataSet()\n",
    "# myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trees.calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#myDat[0][-1] = 'maybe'\n",
    "#myDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trees.calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 按照给定特征划分数据集\n",
    "# 三个输入参数：待划分的数据集，划分数据集的特征，需要返回的特征的值\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    # axis列为value的数据集【该数据集需要排除axis列】\n",
    "    # 判断axis列的值是否为value\n",
    "    for featVec in dataSet:\n",
    "        # chop out axis used for splitting\n",
    "        # [:axis]表示前axis行，即若 axis 为2，就是取 featVec 的前 2 行\n",
    "        if featVec[axis] == value:\n",
    "            reduceFeatVec = featVec[:axis] # 把axis之前的列保存下来\n",
    "            # list.append(object) 向列表中添加一个对象object\n",
    "            # list.extend(sequence) 把一个序列seq的内容添加到列表中\n",
    "            # 1、使用append的时候，是将new_media看作一个对象，整体打包添加到music_media对象中。\n",
    "            # 2、使用extend的时候，是将new_media看作一个序列，将这个序列和music_media序列合并，并放在其后面。\n",
    "            reduceFeatVec.extend(featVec[axis+1:])# [axis+1:]表示从跳过 axis 的 axis+1行，取接下来的数据\n",
    "            retDataSet.append(reduceFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataSet = [[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "# axis = 1\n",
    "# for featVec in dataSet:\n",
    "    # if featVec[axis] == 1:\n",
    "        # reducedFeatVec = featVec[:axis]\n",
    "        # print(reducedFeatVec)\n",
    "        # reducedFeatVec.extend(featVec[axis+1:])\n",
    "        # print(reducedFeatVec)\n",
    "    #print(featVec)\n",
    "    #print(featVec[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选择最好的数据集划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataSet)# 数据集的原始信息熵\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]# 获取对应的feature下的所有数据\n",
    "        uniqueVals = set(featList)# 获取剔重后的集合，使用set对list数据进行去重\n",
    "        newEntropy = 0.0\n",
    "        # 遍历某一列的value集合，计算该列的信息熵 \n",
    "        # 遍历当前特征中的所有唯一属性值，对每个唯一属性值划分一次数据集，计算数据集的新熵值，并对所有唯一特征值得到的熵求和。\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        # gain[信息增益]: 划分数据集前后的信息变化， 获取信息熵最大的值\n",
    "        # 信息增益是熵的减少或者是数据无序度的减少。最后，比较所有特征中的信息增益，返回最好特征划分的索引值。\n",
    "        infoGain = baseEntropy - newEntropy #信息增益\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(trees)\n",
    "#myDat, labels = trees.createDataSet()\n",
    "#trees.chooseBestFeatureToSplit(myDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果只有一列，采用多数表决的方法决定该叶子节点的分类\n",
    "def majorityCnt(classList):\n",
    "    classCount = {} # 初始化字典classCount()\n",
    "    # 对于每一个值，建立键值对（值：次数）\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.key():\n",
    "            classCount[vote] = 0\n",
    "            classCount[vote] +=1\n",
    "    # 对于字典中的键值对，逆序输出（从大到小输出）\n",
    "    sortedClassCount = sorted(classCount.iteritems(),\\\n",
    "                             key = operator.iteritems(1), reverse = True)\n",
    "    return sortedClassCount[0][0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建树的函数代码\n",
    "def createTree(dataSet, labels):\n",
    "    # 取出最后一列的分类结果，如果分类结果中第一个结果存在的数目等于列表的长度，证明只有这一种分类结果，作为分类结果结束。\n",
    "    classList = [example[-1] for example in dataSet\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    # 如果数据集只有1列，那么最初出现label次数最多的一类，作为结果。\n",
    "    # 第二个停止条件：使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组。\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    # 选择最优的列，得到最优列对应的label含义\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    # 获取label的名称\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}} # 初始化MyTree\n",
    "    # 注：labels列表是可变对象，在Python函数中作为参数时传址引用，能够被全局修改\n",
    "    # 所以这行代码导致函数外的同名变量被删除了元素，造成例句无法执行，提示'no surfacing' is not in list‘\n",
    "    del(labels[bestFeat])\n",
    "    # 取出最优列，然后它的分支做分类\n",
    "    featValues = [example[bestFeat] for example in dataSet] # 最优列的特征取值\n",
    "    uniqueValues = set(featValues)\n",
    "    for value in uniqueValues:\n",
    "        subLabels = labels[:]  # 求出剩余的标签label\n",
    "        # 遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数createTree()\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(trees)\n",
    "# myDat, labels = trees.createDataSet()\n",
    "# trees.createTree(myDat, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 测试算法：使用决策树执行分类\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    firstSides = list(inputTree.keys())\n",
    "    firstStr = firstSides[0] # 获取tree的根节点对于的key值\n",
    "    secondDict = inputTree[firstStr] # 除去根节点后的树的分支(通过key得到根节点对应的value)\n",
    "    # 判断根节点名称获取根节点在label中的先后顺序，这样就知道输入的testVec怎么开始对照树来做分类\n",
    "    featIndex = featLabels.index(firstStr) # 获得特征的索引\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__ == 'dict': # 如果值仍为字典，继续分类\n",
    "                classLabel = classify(secondDict[key], featLabels, testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key] #否则，输出对应键的值\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(trees)\n",
    "# myDat, labels = trees.createDataSet()\n",
    "# trees.classify({'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}, labels, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 运行过程中会报错如下：\n",
    "# ValueError: 'no surfacing' is not in list\n",
    "# 主要原因是我先运行 mytree=createtree(data1,labels1)函数，\n",
    "# 而createtree函数在运行过程中回删除标签中已经用过的值，所以导致之后labels不完整，解决方法是再新建一个即可。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
